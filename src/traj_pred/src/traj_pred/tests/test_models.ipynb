{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f906ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.utils import data\n",
    "from trajdata import AgentBatch, AgentType, UnifiedDataset\n",
    "from trajdata.augmentation import NoiseHistories\n",
    "\n",
    "from modules.model_registrar import ModelRegistrar\n",
    "from models.trajectory_predictor import TrajectoryPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54c001a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/pedestrians.json', 'r', encoding=\"utf-8\") as config_json:\n",
    "    hyperparams = json.load(config_json)\n",
    "hyperparams[\"device\"] = \"cpu\"\n",
    "hyperparams[\"edge_encoding\"] = True\n",
    "hyperparams[\"contrastive_weight\"] = 50.0\n",
    "hyperparams[\"history_sec\"] = 2.8\n",
    "hyperparams[\"prediction_sec\"] = 4.8\n",
    "hyperparams[\"incl_robot_node\"] = False\n",
    "hyperparams[\"map_encoding\"] = False\n",
    "hyperparams[\"preprocess_workers\"] = 16\n",
    "hyperparams[\"trajdata_cache_dir\"] = \"../data/pedestrian_datasets/.unified_data_cache\"\n",
    "\n",
    "hyperparams[\"log_p_yt_xz_max\"] = 6\n",
    "hyperparams[\"single_mode_multi_sample\"] = False\n",
    "hyperparams[\"single_mode_multi_sample_num\"] = 50\n",
    "\n",
    "# hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a7a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_data=[\n",
    "    \"eupeds_eth-train\",\n",
    "]\n",
    "data_dirs = {\n",
    "    \"eupeds_eth\": \"~/Projects/trajectron/datasets/eth_ucy_peds\",\n",
    "}\n",
    "\n",
    "attention_radius = defaultdict(\n",
    "    lambda: 20.0\n",
    ")  # Default range is 20m unless otherwise specified.\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 5.0\n",
    "\n",
    "input_noise = 0.0\n",
    "augmentations = list()\n",
    "if input_noise > 0.0:\n",
    "    augmentations.append(NoiseHistories(stddev=input_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda02cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['eupeds_eth-train-zurich', 'cyprus-eupeds_eth-train']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Agent Data (Serially): 100%|██████████| 1/1 [00:00<00:00, 6034.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Agent Data Index (16 CPUs): 100%|██████████| 1/1 [00:00<00:00, 180.60it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 1/1 [00:00<00:00, 920.81it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "dataset = UnifiedDataset(\n",
    "    desired_data=desired_data,\n",
    "    history_sec=(0.1, hyperparams[\"history_sec\"]),\n",
    "    future_sec=(0.1, hyperparams[\"prediction_sec\"]),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams[\"incl_robot_node\"],\n",
    "    incl_raster_map=hyperparams[\"map_encoding\"],\n",
    "    only_predict=[AgentType.PEDESTRIAN],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    augmentations=augmentations if len(augmentations) > 0 else None,\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    cache_location=hyperparams[\"trajdata_cache_dir\"],\n",
    "    data_dirs=data_dirs,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "dataloader = data.DataLoader(\n",
    "    dataset,\n",
    "    collate_fn=dataset.get_collate_fn(pad_format=\"right\"),\n",
    "    pin_memory=False if hyperparams[\"device\"] == \"cpu\" else True,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    sampler=None,\n",
    ")\n",
    "\n",
    "batch: AgentBatch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f516bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Agent Future Length: {batch.agent_fut_len}\")\n",
    "# print(f\"Neigbors Future Length: {batch.neigh_fut_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd6c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./\"\n",
    "model_registrar = ModelRegistrar(model_dir, hyperparams[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eaf7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_predictor = TrajectoryPredictor(\n",
    "    model_registrar, hyperparams, log_writer=None, device=hyperparams[\"device\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19514f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_predictor.set_environment()\n",
    "trajectory_predictor.set_all_annealing_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = None\n",
    "step_scheduler = None\n",
    "# TODO: define a different set of optimization parameter if updating pre-trined model\n",
    "optimizer = optim.Adam(\n",
    "    [\n",
    "        {\n",
    "            \"params\": model_registrar.get_all_but_name_match(\n",
    "                \"map_encoder\"\n",
    "            ).parameters()\n",
    "        },\n",
    "        {\n",
    "            \"params\": model_registrar.get_name_match(\"map_encoder\").parameters(),\n",
    "            \"lr\": hyperparams[\"map_enc_learning_rate\"],\n",
    "        },\n",
    "    ],\n",
    "    lr=hyperparams[\"learning_rate\"],\n",
    ")\n",
    "# Set Learning Rate\n",
    "if hyperparams[\"learning_rate_style\"] == \"const\":\n",
    "    lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=1.0)\n",
    "elif hyperparams[\"learning_rate_style\"] == \"exp\":\n",
    "    lr_scheduler = optim.lr_scheduler.ExponentialLR(\n",
    "        optimizer, gamma=hyperparams[\"learning_decay_rate\"]\n",
    "    )\n",
    "\n",
    "if hyperparams[\"lr_step\"] != 0:\n",
    "    step_scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size=hyperparams[\"lr_step\"], gamma=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "        rank,\n",
    "        model: TrajectoryPredictor,\n",
    "        dataloader,\n",
    "        optimizer,\n",
    "        lr_scheduler,\n",
    "        curr_iter: int,\n",
    "    ):\n",
    "    \"\"\"Backpropagation\"\"\"\n",
    "    pbar = tqdm(\n",
    "        dataloader,\n",
    "        ncols=80,\n",
    "        disable=(rank > 0),\n",
    "    )\n",
    "\n",
    "    batch: AgentBatch\n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        # print(\"\\n----------------------------\")\n",
    "        # print(f\"Batch Index: {batch_idx}\")\n",
    "        model.curr_iter = curr_iter\n",
    "        model.step_all_annealers()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        train_loss, loss_task, loss_nce = model(batch)\n",
    "        pbar.set_description(\n",
    "            f\"Total Loss: {train_loss.detach().item():.4f}, \" +\n",
    "            f\"Task Loss: {loss_task.item():.4f}, \" +\n",
    "            f\"SNCE Loss: {loss_nce.item():.4f}\"\n",
    "        )\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Clipping gradients.\n",
    "        if hyperparams[\"grad_clip\"] is not None:\n",
    "            nn.utils.clip_grad_value_(\n",
    "                model_registrar.parameters(), hyperparams[\"grad_clip\"]\n",
    "            )\n",
    "\n",
    "        # Stepping forward the learning rate scheduler and annealers.\n",
    "        lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_iter = 0\n",
    "curr_iter = train_one_epoch(\n",
    "    rank=0,\n",
    "    model=trajectory_predictor,\n",
    "    dataloader=dataloader,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    curr_iter=curr_iter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6e26aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
