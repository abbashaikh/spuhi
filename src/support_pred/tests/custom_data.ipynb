{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781211d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "from typing import Tuple, List, Optional, Callable\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils import data\n",
    "from trajdata import UnifiedDataset, SceneBatch, AgentBatch\n",
    "from trajdata.data_structures.batch_element import SceneBatchElement\n",
    "from trajdata.data_structures.agent import AgentMetadata, AgentType\n",
    "from trajdata.data_structures.state import StateArray\n",
    "from trajdata.augmentation import NoiseHistories\n",
    "from trajdata.utils.state_utils import transform_state_np_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0728cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_agent_hist(\n",
    "    batch_elem: SceneBatchElement,\n",
    "    history_sec: Tuple[Optional[float], Optional[float]],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"agent’s history transformed into agent-centric coordinates\"\"\"\n",
    "    dt = batch_elem.dt\n",
    "    max_hist_len: int = round((history_sec[1]/dt)) + 1\n",
    "    world_agent_hist: List[np.ndarray] = batch_elem.agent_histories\n",
    "    state_dim = world_agent_hist[0].shape[-1]\n",
    "\n",
    "    agent_pos_list = [hist[-1,:2] for hist in world_agent_hist]\n",
    "    agent_sc_list = [hist[-1,-2:] for hist in world_agent_hist]\n",
    "\n",
    "    agents_hist_st: List[np.ndarray] = []\n",
    "    for idx, (pos, sc) in enumerate(zip(agent_pos_list, agent_sc_list)):\n",
    "        cos_agent = sc[-1]\n",
    "        sin_agent = sc[-2]\n",
    "        centered_world_from_agent_tf: np.ndarray = np.array(\n",
    "            [\n",
    "                [cos_agent, -sin_agent, pos[0]],\n",
    "                [sin_agent, cos_agent, pos[1]],\n",
    "                [0.0, 0.0, 1.0],\n",
    "            ]\n",
    "        )\n",
    "        centered_agent_from_world_tf: np.ndarray = np.linalg.inv(\n",
    "            centered_world_from_agent_tf\n",
    "        )\n",
    "        hist = world_agent_hist[idx]\n",
    "        hist_st = transform_state_np_2d(hist, centered_agent_from_world_tf)\n",
    "\n",
    "        t_i = hist_st.shape[0]\n",
    "        if t_i<max_hist_len:\n",
    "            padding = np.full((max_hist_len-t_i, state_dim), np.nan, dtype=hist_st.dtype)\n",
    "            hist_st_padded = np.concatenate([padding, hist_st], axis=0)\n",
    "        else:\n",
    "            hist_st_padded = hist_st[:max_hist_len]\n",
    "        agents_hist_st.append(hist_st_padded)\n",
    "\n",
    "    return np.stack(agents_hist_st, axis=0)\n",
    "\n",
    "def get_neighs(\n",
    "    batch_elem: SceneBatchElement,\n",
    "    interaction_radius: float,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Provides adjacency matrix\"\"\"\n",
    "    agents: List[AgentMetadata] = batch_elem.agents\n",
    "    curr_states = []\n",
    "    for agent in agents:\n",
    "        raw_state: StateArray = batch_elem.cache.get_raw_state(\n",
    "            agent.name, batch_elem.scene_ts\n",
    "        )\n",
    "        state = np.asarray(raw_state)\n",
    "        curr_states.append(state)\n",
    "\n",
    "    is_neigh = []\n",
    "    for state in curr_states:\n",
    "        distances = [\n",
    "            np.linalg.norm(state[:2] - agent_st[:2])\n",
    "            for agent_st in curr_states\n",
    "        ]\n",
    "        is_neigh.append([dist <= interaction_radius for dist in distances])\n",
    "    is_neigh_mat = np.stack(is_neigh, axis=0)\n",
    "    np.fill_diagonal(is_neigh_mat, False)\n",
    "\n",
    "    return is_neigh_mat\n",
    "\n",
    "def per_agent_neigh_hist(\n",
    "    batch_elem: SceneBatchElement,\n",
    "    history_sec: Tuple[Optional[float], Optional[float]],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Provide neighbor history of each agent in scene\n",
    "    in respective agent-centric frames\n",
    "    \"\"\"\n",
    "    assert batch_elem.standardize_data is False, \\\n",
    "        \"Per-agent history requires a non-standarized dataset (set standardize_data=False)\"\n",
    "\n",
    "    dt = batch_elem.dt\n",
    "    max_hist_len: int = round((history_sec[1]/dt)) + 1\n",
    "    world_agent_hist: List[np.ndarray] = batch_elem.agent_histories\n",
    "    state_dim = world_agent_hist[0].shape[-1]\n",
    "    num_agents = batch_elem.num_agents\n",
    "\n",
    "    agent_pos_list = [hist[-1,:2] for hist in world_agent_hist]\n",
    "    agent_sc_list = [hist[-1,-2:] for hist in world_agent_hist]\n",
    "\n",
    "    neigh_hists: List[List[np.ndarray]] = []\n",
    "    for idx, (pos, sc) in enumerate(zip(agent_pos_list, agent_sc_list)):\n",
    "        # calculate transformation matrix to go from world frame to agent frame\n",
    "        cos_agent = sc[-1]\n",
    "        sin_agent = sc[-2]\n",
    "        centered_world_from_agent_tf: np.ndarray = np.array(\n",
    "            [\n",
    "                [cos_agent, -sin_agent, pos[0]],\n",
    "                [sin_agent, cos_agent, pos[1]],\n",
    "                [0.0, 0.0, 1.0],\n",
    "            ]\n",
    "        )\n",
    "        centered_agent_from_world_tf: np.ndarray = np.linalg.inv(\n",
    "            centered_world_from_agent_tf\n",
    "        )\n",
    "\n",
    "        row_hists: List[Optional[np.ndarray]] = []\n",
    "        for jdx, agent_hist in enumerate(world_agent_hist):\n",
    "            # skip self\n",
    "            if jdx == idx:\n",
    "                continue\n",
    "            # append if neighbor\n",
    "            if batch_elem.extras[\"is_neigh\"][idx, jdx]:\n",
    "                hist_st = transform_state_np_2d(agent_hist, centered_agent_from_world_tf)\n",
    "                row_hists.append(hist_st)\n",
    "            # else append None\n",
    "            else:\n",
    "                row_hists.append(None)\n",
    "        neigh_hists.append(row_hists)\n",
    "\n",
    "    output = np.full((num_agents, num_agents-1, max_hist_len, state_dim), np.nan, dtype=float)\n",
    "    # pad arrays to match maximum history length (8 steps),\n",
    "    # and max possible neighbors (num of agents - 1)\n",
    "    for i in range(num_agents):\n",
    "        for k, hist_ij in enumerate(neigh_hists[i]):\n",
    "            if hist_ij is None:\n",
    "                continue\n",
    "            len_j = hist_ij.shape[0]\n",
    "            output[i, k, -len_j:, :] = hist_ij\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d9ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extras_collate_fn(\n",
    "    batch_elems: List[SceneBatchElement],\n",
    "    history_sec: Tuple[Optional[float], Optional[float]],\n",
    "    base_collate: Callable[[List[SceneBatchElement]], SceneBatch],\n",
    ") -> SceneBatch:\n",
    "    \"\"\"\n",
    "    1) Pads each extra (“agent_hist_st”, “is_neigh”, “neigh_hist”) \n",
    "    2) Calls base_collate(...) (i.e. scene_collate_fn) on the padded batch.\n",
    "    \"\"\"\n",
    "    max_agent_num: int = max(elem.num_agents for elem in batch_elems) # M\n",
    "    dt = batch_elems[0].dt\n",
    "    max_hist_len: int = round((history_sec[1]/dt)) + 1\n",
    "    state_dim = batch_elems[0].agent_histories[0].shape[-1]\n",
    "\n",
    "    for elem in batch_elems:\n",
    "        n_i = elem.num_agents\n",
    "        agent_hist = elem.extras.get(\"agent_hist_st\")\n",
    "        mat = elem.extras[\"is_neigh\"]\n",
    "        neigh_hist = elem.extras[\"neigh_hist\"]\n",
    "\n",
    "        if n_i < max_agent_num:\n",
    "            # Pad \"agent_hist_st\": shape (n_i, max_hist_len, 8) -> (M, max_hist_len, 8)\n",
    "            pad_agent_hist = np.full(\n",
    "                (max_agent_num-n_i, max_hist_len, state_dim),\n",
    "                np.nan,\n",
    "                dtype=agent_hist.dtype\n",
    "            )\n",
    "            padded_agent_hist = np.concatenate([agent_hist, pad_agent_hist], axis=0)\n",
    "            # Pad \"is_neigh\": shape (n_i, n_i) -> (max_agents_in_batch, max_agents_in_batch)\n",
    "            pad_mat = np.zeros((max_agent_num, max_agent_num), dtype=mat.dtype)\n",
    "            pad_mat[:n_i, :n_i] = mat\n",
    "            elem.extras[\"is_neigh\"] = pad_mat\n",
    "            # Pad \"neigh_hist\": shape (n_i, n_i-1, max_hist_len, 8) -> (M, M-1, max_hist_len, 8)\n",
    "            padded_neigh_hist = np.full(\n",
    "                (max_agent_num, max_agent_num-1, max_hist_len, state_dim),\n",
    "                np.nan,\n",
    "                dtype=neigh_hist.dtype\n",
    "            )\n",
    "            padded_neigh_hist[:n_i, :(n_i - 1), :, :] = neigh_hist\n",
    "        else:\n",
    "            padded_agent_hist = agent_hist[:max_agent_num]\n",
    "            elem.extras[\"is_neigh\"] = mat[:max_agent_num, :max_agent_num]\n",
    "            padded_neigh_hist = neigh_hist[:max_agent_num]\n",
    "\n",
    "        elem.extras[\"agent_hist_st\"] = padded_agent_hist\n",
    "        elem.extras[\"neigh_hist\"] = padded_neigh_hist\n",
    "\n",
    "    return base_collate(batch_elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f046949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['eupeds_eth-zurich-train', 'eupeds_eth-train-cyprus']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Agent Data (Serially): 100%|██████████| 1/1 [00:00<00:00, 13066.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Scene Data Index (16 CPUs): 100%|██████████| 1/1 [00:00<00:00, 147.55it/s]\n",
      "Structuring Scene Data Index: 100%|██████████| 1/1 [00:00<00:00, 28339.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Data Samples: 674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "log_dir = '../../../data/trained_models/trajectory_prediction'\n",
    "model_dir = os.path.join(log_dir, \"eth-28_May_2025_10_28_45\")\n",
    "\n",
    "with open(os.path.join(model_dir, 'config.json'), 'r', encoding=\"utf-8\") as config_json:\n",
    "    hyperparams = json.load(config_json)\n",
    "# device\n",
    "hyperparams[\"device\"] = \"cpu\"\n",
    "hyperparams[\"trajdata_cache_dir\"] = \"../../../data/pedestrian_datasets/.unified_data_cache\"\n",
    "\n",
    "desired_data=[\n",
    "    \"eupeds_eth-train\",\n",
    "]\n",
    "max_agent_num=20\n",
    "data_dirs = {\n",
    "    \"eupeds_eth\": \"../../../data/pedestrian_datasets/eth_ucy_peds\",\n",
    "}\n",
    "\n",
    "attention_radius = defaultdict(\n",
    "    lambda: 20.0\n",
    ")  # Default range is 20m unless otherwise specified.\n",
    "# attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 5.0\n",
    "interaction_radius = 5.0\n",
    "\n",
    "history_sec = (0.1, hyperparams[\"history_sec\"])\n",
    "future_sec = (0.1, hyperparams[\"prediction_sec\"])\n",
    "\n",
    "input_noise = 0.0\n",
    "augmentations = list()\n",
    "if input_noise > 0.0:\n",
    "    augmentations.append(NoiseHistories(stddev=input_noise))\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "dataset = UnifiedDataset(\n",
    "    desired_data=desired_data,\n",
    "    centric=\"scene\",\n",
    "    # centric=\"agent\",\n",
    "    max_agent_num=max_agent_num,\n",
    "    history_sec=history_sec,\n",
    "    future_sec=future_sec,\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams[\"incl_robot_node\"],\n",
    "    incl_raster_map=hyperparams[\"map_encoding\"],\n",
    "    only_predict=[AgentType.PEDESTRIAN],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    augmentations=augmentations if len(augmentations) > 0 else None,\n",
    "    standardize_data=False,\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    cache_location=hyperparams[\"trajdata_cache_dir\"],\n",
    "    data_dirs=data_dirs,\n",
    "    verbose=True,\n",
    "    extras={\n",
    "        \"agent_hist_st\": partial(custom_agent_hist, history_sec=history_sec),\n",
    "        \"is_neigh\": partial(get_neighs, interaction_radius=interaction_radius),\n",
    "        \"neigh_hist\": partial(per_agent_neigh_hist, history_sec=history_sec),\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"# Data Samples: {len(dataset):,}\")\n",
    "\n",
    "base_collate = dataset.get_collate_fn(pad_format=\"right\")\n",
    "\n",
    "dataloader = data.DataLoader(\n",
    "    dataset,\n",
    "    # collate_fn=dataset.get_collate_fn(pad_format=\"right\"),\n",
    "    collate_fn=partial(\n",
    "            extras_collate_fn,\n",
    "            history_sec=history_sec,\n",
    "            base_collate=base_collate\n",
    "    ),\n",
    "    pin_memory=False if hyperparams[\"device\"] == \"cpu\" else True,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    sampler=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d52402c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch: SceneBatch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "435bc775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_idx', 'scene_ts', 'dt', 'num_agents', 'agent_type', 'centered_agent_state', 'agent_names', 'agent_hist', 'agent_hist_extent', 'agent_hist_len', 'agent_fut', 'agent_fut_extent', 'agent_fut_len', 'robot_fut', 'robot_fut_len', 'map_names', 'maps', 'maps_resolution', 'vector_maps', 'rasters_from_world_tf', 'centered_agent_from_world_tf', 'centered_world_from_agent_tf', 'scene_ids', 'history_pad_dir', 'extras'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "871dec01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of agents in scenes: tensor([2, 7, 4, 1])\n",
      "Shape of agent_hist_st array: torch.Size([4, 7, 8, 8])\n",
      "Shape of is_neigh array: torch.Size([4, 7, 7])\n",
      "Shape of neigh hist array: torch.Size([4, 7, 6, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num of agents in scenes: {batch.num_agents}\")\n",
    "print(f\"Shape of agent_hist_st array: {batch.extras['agent_hist_st'].shape}\")\n",
    "print(f\"Shape of is_neigh array: {batch.extras['is_neigh'].shape}\")\n",
    "print(f\"Shape of neigh hist array: {batch.extras['neigh_hist'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bff2e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SceneAgentBatch:\n",
    "    def __init__(self, batch: SceneBatch):\n",
    "        self.batch = batch\n",
    "        self.num_agents = self.batch.num_agents\n",
    "        self.num_scenes = self.num_agents.shape[0]\n",
    "        self.agent_hist_st = batch.extras['agent_hist_st']\n",
    "    \n",
    "    @property\n",
    "    def dt(self) -> torch.Tensor:\n",
    "        return self.batch.dt\n",
    "\n",
    "    @property\n",
    "    def agent_hist(self) -> torch.Tensor:\n",
    "        agent_hist: List[torch.Tensor] = []\n",
    "        for idx, num_agents in enumerate(self.batch.num_agents):\n",
    "            for jdx in range(num_agents):\n",
    "                agent_hist.append(self.agent_hist_st[idx, jdx])\n",
    "\n",
    "        return torch.stack(agent_hist, dim=0)\n",
    "    \n",
    "    @property\n",
    "    def agent_hist_len(self) -> torch.Tensor:\n",
    "        return batch.agent_hist_len[batch.agent_hist_len!=0]\n",
    "    \n",
    "    @property\n",
    "    def num_neigh(self) -> torch.Tensor:\n",
    "        is_neigh = self.batch.extras['is_neigh']\n",
    "        num_neigh: List[torch.Tensor] = []\n",
    "        for idx in range(self.num_scenes):\n",
    "            n_i = self.num_agents[idx].item()\n",
    "            submat = is_neigh[idx, :n_i, :n_i]\n",
    "            counts_per_agent = submat.sum(dim=1).to(torch.long)\n",
    "            num_neigh.append(counts_per_agent)\n",
    "        return torch.cat(num_neigh, dim=0)\n",
    "    \n",
    "    @property\n",
    "    def neigh_hist(self) -> torch.Tensor:\n",
    "        grouped_neigh_hist = self.batch.extras['neigh_hist']\n",
    "        max_num_neigh: int = self.num_neigh.max().item()\n",
    "\n",
    "        neigh_hist: List[torch.Tensor] = []\n",
    "        for scene_idx in range(self.num_scenes):\n",
    "            n_i = self.num_agents[scene_idx].item()\n",
    "            for agent_idx in range(n_i):\n",
    "                neigh_hist.append(grouped_neigh_hist[scene_idx, agent_idx, :max_num_neigh])\n",
    "        \n",
    "        return torch.stack(neigh_hist)\n",
    "\n",
    "    @property\n",
    "    def neigh_hist_len(self) -> torch.Tensor:\n",
    "        is_neigh = self.batch.extras['is_neigh']\n",
    "        batch_size = self.agent_hist.shape[0]\n",
    "        max_num_neigh: int = self.num_neigh.max().item()\n",
    "\n",
    "        device = self.agent_hist_len.device\n",
    "        dtype = self.agent_hist_len.dtype\n",
    "        \n",
    "        neigh_hist_len_list: List[torch.Tensor] = []\n",
    "        for scene_idx in range(self.num_scenes):\n",
    "            n_i = self.num_agents[scene_idx].item()\n",
    "            for agent_idx in range(n_i):\n",
    "                neigh_mask = is_neigh[scene_idx, agent_idx, :n_i]\n",
    "                neighbor_idxs = torch.nonzero(neigh_mask, as_tuple=False).view(-1)\n",
    "                hist_lens = self.batch.agent_hist_len[scene_idx, neighbor_idxs]\n",
    "                neigh_hist_len_list.append(hist_lens)\n",
    "\n",
    "        output = torch.zeros((batch_size, max_num_neigh), dtype=dtype, device=device)\n",
    "\n",
    "        for idx, hist_lens in enumerate(neigh_hist_len_list):\n",
    "            k = hist_lens.size(0)\n",
    "            if k > 0:\n",
    "                output[idx, :k] = hist_lens.to(device)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    @property\n",
    "    def neigh_types(self) -> torch.Tensor:\n",
    "        is_neigh = self.batch.extras['is_neigh']\n",
    "        agent_types = self.batch.agent_type\n",
    "        batch_size = self.agent_hist.shape[0]\n",
    "        max_num_neigh: int = self.num_neigh.max().item()\n",
    "\n",
    "        device = self.agent_hist_len.device\n",
    "        dtype = self.agent_hist_len.dtype\n",
    "\n",
    "        neigh_types_list: List[torch.Tensor] = []\n",
    "        for scene_idx in range(self.num_scenes):\n",
    "            n_i = self.num_agents[scene_idx].item()\n",
    "            for agent_idx in range(n_i):\n",
    "                neigh_mask = is_neigh[scene_idx, agent_idx, :n_i]\n",
    "                neighbor_idxs = torch.nonzero(neigh_mask, as_tuple=False).view(-1)\n",
    "                row_types = agent_types[scene_idx, neighbor_idxs]\n",
    "                neigh_types_list.append(row_types)\n",
    "\n",
    "        output = torch.full(\n",
    "            (batch_size, max_num_neigh),\n",
    "            -1.0,\n",
    "            dtype=dtype,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        for idx, types in enumerate(neigh_types_list):\n",
    "            k = types.size(0)\n",
    "            if k > 0:\n",
    "                output[idx, :k] = types.to(device)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c002ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_batch = SceneAgentBatch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97679ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Functions\n",
    "# To Calculate Number of Samples\n",
    "\n",
    "import warnings\n",
    "\n",
    "def bisection(N_low, N_high, sample_function):\n",
    "    \"\"\"\n",
    "    :param N_low: Low guess for the intersection\n",
    "    :param N_high: High guess for the intersection\n",
    "    :param sample_function: Function for which to find the zero crossing\n",
    "    :return: The zero crossing\n",
    "    \"\"\"\n",
    "    # print(f\"Running bisection to find S between {N_low} and {N_high}...\", end=\"\")\n",
    "\n",
    "    a = N_low\n",
    "    b = N_high\n",
    "    f = sample_function\n",
    "\n",
    "    TOL = 1e-9\n",
    "\n",
    "    if a > b:\n",
    "      print('Error: a > b!')\n",
    "      return -1\n",
    "\n",
    "    value_a = f(a)\n",
    "\n",
    "    for i in range(1000):\n",
    "      c = (a + b) / 2.\n",
    "      value_c = f(c)\n",
    "\n",
    "      if value_c == 0 or (b - a) / 2. < TOL:\n",
    "          # print(f\" Found {c:.2f}\")\n",
    "          return c\n",
    "\n",
    "      if np.sign(value_c) == np.sign(value_a):\n",
    "          a = c\n",
    "          value_a = value_c\n",
    "      else:\n",
    "          b = c\n",
    "\n",
    "    print(\"Bisection failed to converge!\")\n",
    "\n",
    "def nchoosek_rooted(n, k, root):\n",
    "    \"\"\"\n",
    "    To avoid numerical errors, an implementation of N choose K where the root is resolved in between\n",
    "    :return: (n choose k)^(1/root)\n",
    "    \"\"\"\n",
    "    y = 1.0\n",
    "    for i in range(k):\n",
    "        y = y * ((n - (k - i - 1.)) / (k - i))**(1. / root)\n",
    "    return y\n",
    "\n",
    "def compute_risk(S, confidence, support):\n",
    "  with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    return 1. - ((confidence / S) ** (1. / (S - support))) * (1. / nchoosek_rooted(S, support, S - support))\n",
    "\n",
    "def find_sample_size(support, risk, confidence):\n",
    "  risk_function = lambda S, support: compute_risk(S, confidence, support)      # Scenario Optimization guarantee for any support\n",
    "  max_risk_function = lambda S: risk - risk_function(S, support)               # \"\" for the specified support limit\n",
    "\n",
    "  S_low = support+1\n",
    "  S_high = 500000\n",
    "\n",
    "  S_double = bisection(S_low, S_high, max_risk_function)\n",
    "  S = np.floor(S_double) + 1\n",
    "\n",
    "  return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d790a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "# To ensure humans do not collide with the robot during initialization\n",
    "# and are within field of view of the robot\n",
    "\n",
    "def is_within_distance(pos1, pos2, distance):\n",
    "    return np.linalg.norm(np.array(pos1) - np.array(pos2)) <= distance\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\"Calculate the angle between two vectors.\"\"\"\n",
    "    v1_u = v1 / np.linalg.norm(v1)\n",
    "    v2_u = v2 / np.linalg.norm(v2)\n",
    "    angle = np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "    cross = np.cross(np.append(v1_u, 0), np.append(v2_u, 0))\n",
    "    if cross[2] < 0:\n",
    "        angle = -angle\n",
    "    return angle\n",
    "\n",
    "def is_within_fov(robot_pos, robot_orientation, target_pos, fov=90):\n",
    "    \"\"\"Check if target_pos is within the field of view of the robot.\"\"\"\n",
    "    direction_vector = np.array([np.cos(np.deg2rad(robot_orientation)), np.sin(np.deg2rad(robot_orientation))])\n",
    "    target_vector = np.array(target_pos) - np.array(robot_pos)\n",
    "    angle = np.rad2deg(angle_between(direction_vector, target_vector))\n",
    "    return -fov/2 < angle < fov/2\n",
    "\n",
    "# To generate constraint coefficients given human and robot positions\n",
    "def get_constraint_coeff(robot_pos, human_pos, r):\n",
    "    u = human_pos - robot_pos\n",
    "    A = u / np.linalg.norm(u)\n",
    "    a = A[0]\n",
    "    b = A[1]\n",
    "    c = r - A[0]*human_pos[0] - A[1]*human_pos[1]\n",
    "    return np.array([a, b, c]) # Linear inequality: ax + by + c <= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae032a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_symmetric(matrix):\n",
    "    \"\"\"\n",
    "    Checks if the given matrix is symmetric (A == A^T).\n",
    "    Raises a ValueError if it is not symmetric.\n",
    "    \"\"\"\n",
    "    if not np.allclose(matrix, matrix.T):  # Checks if A == A^T (within numerical tolerance)\n",
    "        raise ValueError(\"Matrix is not symmetric!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a8aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from traj_pred.modules import ModelRegistrar\n",
    "from traj_pred import TrajectoryPredictor\n",
    "\n",
    "# Function to load the trajectron model\n",
    "def load_model(epoch: int):\n",
    "    while epoch > 0:\n",
    "        save_path = Path(model_dir) / f'model_registrar-{epoch}.pt'\n",
    "        if save_path.is_file():\n",
    "            break\n",
    "        epoch -= 1\n",
    "\n",
    "    model_registrar = ModelRegistrar(model_dir, hyperparams[\"device\"])\n",
    "\n",
    "    model = TrajectoryPredictor(\n",
    "        model_registrar=model_registrar,\n",
    "        hyperparams=hyperparams,\n",
    "        log_writer=None,\n",
    "        device=hyperparams[\"device\"])\n",
    "    model.set_environment()\n",
    "\n",
    "    checkpoint = torch.load(save_path, map_location=hyperparams[\"device\"])\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
    "\n",
    "    return model\n",
    "\n",
    "epoch = 15\n",
    "\n",
    "traj_predictor = load_model(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Function\n",
    "## To get predictions for a scene\n",
    "## and calculate the constraint coefficients\n",
    "\n",
    "col_radius = 1.0  # Collision radius for agents\n",
    "buffer_dist = 0.5 # Buufer distance considered when choosing robot position\n",
    "vision_radius = 12.0  # Vision radius for robots\n",
    "ph = 12\n",
    "\n",
    "def get_scene_graph_data(batch: SceneBatch, scene_data):\n",
    "    enc = traj_predictor.get_encoding(batch) # TODO\n",
    "    preds = traj_predictor.incremental_forward(\n",
    "        batch=batch,\n",
    "        prediction_horizon=ph,\n",
    "        num_samples=1,\n",
    "        full_dist=True\n",
    "    )\n",
    "\n",
    "    # All humans in the scene\n",
    "    scene_data[\"Human Positions\"] = obs.curr_agent_state[:, :2].cpu().numpy()\n",
    "\n",
    "    # Agent to World frame transformations\n",
    "    agents_to_world_tf = obs.agents_from_world_tf[:, :2, :2].cpu().numpy()\n",
    "    # Append predicted positions of humans to occupied positions\n",
    "    occupied_pos = [pos for pos in scene_data[\"Human Positions\"]]\n",
    "    # Initiate adjaceny matrix\n",
    "    adjacency_matrix = np.zeros((len(obs.agent_name), len(obs.agent_name)), dtype=int)\n",
    "\n",
    "    # Loop through all humans\n",
    "    for idx, human in enumerate(obs.agent_name):\n",
    "        # Append predicted positions to occupied positions (after transformation to world frame)\n",
    "        pred_world_frame = pred[human].reshape(prediction_horizon, 2) @ agents_to_world_tf[idx, :, :] + scene_data[\"Human Positions\"][idx, :]\n",
    "        for jdx in range(prediction_horizon):\n",
    "            occupied_pos.append(pred_world_frame[jdx, :])\n",
    "        # Create adjacency matrix\n",
    "        current_state = scene_data[\"Human Positions\"][idx, :2]\n",
    "        agent_to_world_tf = agents_to_world_tf[idx, :, :]\n",
    "        if obs.num_neigh[idx] > 0:\n",
    "            for neigh_pos in obs.neigh_hist[idx, :obs.num_neigh[idx].item(), -1, :2].cpu().numpy():\n",
    "                neigh_pos = neigh_pos @ agent_to_world_tf + current_state\n",
    "                for jdx, agent_pos in enumerate(obs.curr_agent_state[:, :2].cpu().numpy()):\n",
    "                    if np.linalg.norm(neigh_pos - agent_pos) < 1e-5:\n",
    "                        adjacency_matrix[idx, jdx] = 1\n",
    "        # Store human encodings\n",
    "        scene_data[\"Encodings\"].append(enc[human].cpu().numpy().flatten())\n",
    "\n",
    "    scene_data[\"Adjacency Matrix\"] = adjacency_matrix\n",
    "    check_symmetric(scene_data[\"Adjacency Matrix\"])\n",
    "\n",
    "    # Assign appropriate robot position\n",
    "    # print(\"Occupied positions:\", occupied_pos)\n",
    "    while True: # Generate a random position for the robot\n",
    "        # Ensure the robot's position does not overlap with any occupied positions\n",
    "        robot_position = (random.uniform(-vision_radius, vision_radius), random.uniform(-vision_radius, vision_radius))\n",
    "        if not any(is_within_distance(robot_position, pos, col_radius+buffer_dist) for pos in occupied_pos):\n",
    "            break\n",
    "    scene_data[\"Robot Pose\"] = [robot_position[0], robot_position[1]]\n",
    "\n",
    "    return obs, scene_data\n",
    "\n",
    "\n",
    "def get_constr_data(t, S, obs: AgentBatch, scene_data):\n",
    "\n",
    "    _, preds, _, _ = trajectron.incremental_forward(\n",
    "        timestep=t,\n",
    "        obs=obs,\n",
    "        maps=None,\n",
    "        prediction_horizon=prediction_horizon,\n",
    "        num_samples=int(S),\n",
    "        full_dist=False\n",
    "    )\n",
    "\n",
    "    # Agent to World frame transformations\n",
    "    agents_to_world_tf = obs.agents_from_world_tf[:, :2, :2].cpu().numpy()\n",
    "\n",
    "    constraint_coeffs = []\n",
    "    for idx, human in enumerate(obs.agent_name):\n",
    "        # print(\"Pred shape:\", preds[human].shape)\n",
    "        constraint_pos_st = preds[human][:, :, 0, :].reshape(int(S), 2) # TODO: change the timestpe of prediction positions being considered\n",
    "        constraint_pos = constraint_pos_st @ agents_to_world_tf[idx, :, :] + scene_data[\"Human Positions\"][idx, :]\n",
    "        # print(\"Constraint positions:\", constraint_pos)\n",
    "        for sidx in range(int(S)):\n",
    "            constraint_coeffs.append(get_constraint_coeff(scene_data[\"Robot Pose\"], constraint_pos[sidx, :], col_radius))\n",
    "            # print(\"Constraint Coeffs:\", constraint_coeffs[-1])\n",
    "    scene_data[\"Constraint Coefficients\"] = constraint_coeffs\n",
    "  \n",
    "    return scene_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test constraint calculation\n",
    "scene_data: Dict[str, List] = {\n",
    "                \"Robot Pose\": None,\n",
    "                \"Human Positions\": [],\n",
    "                \"Adjacency Matrix\": None,\n",
    "                \"Encodings\": [],\n",
    "                }\n",
    "test_t=287\n",
    "obs, scene_data = get_scene_graph_data(test_t, scene_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_data[\"Constraint Coefficients\"] = None\n",
    "scene_data = get_constr_data(test_t, 10, obs, scene_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
