{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd7c6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils import data\n",
    "from trajdata import AgentBatch, AgentType, UnifiedDataset, SceneBatch\n",
    "from trajdata.augmentation import NoiseHistories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62968bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = '../../../data/trained_models/trajectory_prediction'\n",
    "model_dir = os.path.join(log_dir, \"eth-28_May_2025_10_28_45\")\n",
    "\n",
    "with open(os.path.join(model_dir, 'config.json'), 'r', encoding=\"utf-8\") as config_json:\n",
    "    hyperparams = json.load(config_json)\n",
    "# device\n",
    "hyperparams[\"device\"] = \"cpu\"\n",
    "hyperparams[\"trajdata_cache_dir\"] = \"../../../data/pedestrian_datasets/.unified_data_cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4f71c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_data=[\n",
    "    \"eupeds_eth-train_loo\",\n",
    "]\n",
    "data_dirs = {\n",
    "    \"eupeds_eth\": \"../../../data/pedestrian_datasets/eth_ucy_peds\",\n",
    "}\n",
    "\n",
    "attention_radius = defaultdict(\n",
    "    lambda: 20.0\n",
    ")  # Default range is 20m unless otherwise specified.\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 5.0\n",
    "\n",
    "input_noise = 0.0\n",
    "augmentations = list()\n",
    "if input_noise > 0.0:\n",
    "    augmentations.append(NoiseHistories(stddev=input_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308df11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Data Samples: 4,356\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "\n",
    "dataset = UnifiedDataset(\n",
    "    desired_data=desired_data,\n",
    "    centric=\"scene\",\n",
    "    history_sec=(0.1, hyperparams[\"history_sec\"]),\n",
    "    future_sec=(0.1, hyperparams[\"prediction_sec\"]),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams[\"incl_robot_node\"],\n",
    "    incl_raster_map=hyperparams[\"map_encoding\"],\n",
    "    only_predict=[AgentType.PEDESTRIAN],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    augmentations=augmentations if len(augmentations) > 0 else None,\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    cache_location=hyperparams[\"trajdata_cache_dir\"],\n",
    "    data_dirs=data_dirs,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(f\"# Data Samples: {len(dataset):,}\")\n",
    "\n",
    "dataloader = data.DataLoader(\n",
    "    dataset,\n",
    "    collate_fn=dataset.get_collate_fn(pad_format=\"right\"),\n",
    "    pin_memory=False if hyperparams[\"device\"] == \"cpu\" else True,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    sampler=None,\n",
    ")\n",
    "\n",
    "batch: SceneBatch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d31f2166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data_idx', 'scene_ts', 'dt', 'num_agents', 'agent_type', 'centered_agent_state', 'agent_names', 'agent_hist', 'agent_hist_extent', 'agent_hist_len', 'agent_fut', 'agent_fut_extent', 'agent_fut_len', 'robot_fut', 'robot_fut_len', 'map_names', 'maps', 'maps_resolution', 'vector_maps', 'rasters_from_world_tf', 'centered_agent_from_world_tf', 'centered_world_from_agent_tf', 'scene_ids', 'history_pad_dir', 'extras'])\n"
     ]
    }
   ],
   "source": [
    "print(batch.__dict__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44265e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene ID: ['crowds_zara02_train']\n",
      "Scene Timestep: tensor([709], dtype=torch.int32)\n",
      "Data Idx: tensor([2278], dtype=torch.int32)\n",
      "Num. of Agents: tensor([10])\n",
      "Agent Names: [['69', '70', '112', '111', '135', '132', '133', '134', '131', '130']]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Scene ID: {batch.scene_ids}\")\n",
    "print(f\"Scene Timestep: {batch.scene_ts}\")\n",
    "print(f\"Data Idx: {batch.data_idx}\")\n",
    "print(f\"Num. of Agents: {batch.num_agents}\")\n",
    "print(f\"Agent Names: {batch.agent_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1fa26268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centered Agent States: StateTensorXYXdYdXddYddH([[ 6.0103e+00,  4.9131e+00, -8.9448e-03, -5.3698e-03,\n",
      "                           -5.5511e-15,  5.5511e-15, -2.6009e+00]],\n",
      "                         dtype=torch.float64)\n",
      "Agent History Lengths: tensor([[8, 8, 8, 8, 8, 8, 8, 8, 8, 8]])\n",
      "Agent Future Lengths: tensor([[12, 12, 12, 12, 12,  7, 12, 12, 12, 12]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Centered Agent States: {batch.centered_agent_state}\")\n",
    "print(f\"Agent History Lengths: {batch.agent_hist_len}\")\n",
    "print(f\"Agent Future Lengths: {batch.agent_fut_len}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07764877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent History Shape: torch.Size([1, 10, 8, 8])\n",
      "Agent Future Shape: torch.Size([1, 10, 12, 8])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Agent History Shape: {batch.agent_hist.shape}\")\n",
    "print(f\"Agent Future Shape: {batch.agent_fut.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce2130dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from traj_pred.modules import ModelRegistrar\n",
    "from traj_pred import TrajectoryPredictor\n",
    "\n",
    "# Function to load the trajectron model\n",
    "def load_model(epoch: int):\n",
    "    while epoch > 0:\n",
    "        save_path = Path(model_dir) / f'model_registrar-{epoch}.pt'\n",
    "        if save_path.is_file():\n",
    "            break\n",
    "        epoch -= 1\n",
    "\n",
    "    model_registrar = ModelRegistrar(model_dir, hyperparams[\"device\"])\n",
    "\n",
    "    trained_model = TrajectoryPredictor(\n",
    "        model_registrar=model_registrar,\n",
    "        hyperparams=hyperparams,\n",
    "        log_writer=False,\n",
    "        device=hyperparams[\"device\"]\n",
    "    )\n",
    "    trained_model.set_environment()\n",
    "\n",
    "    checkpoint = torch.load(save_path, map_location=hyperparams[\"device\"])\n",
    "    trained_model.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
    "\n",
    "    return trained_model\n",
    "\n",
    "epoch = 15\n",
    "\n",
    "traj_predictor: TrajectoryPredictor = load_model(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fde6afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(traj_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7fe23e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Functions\n",
    "# To Calculate Number of Samples\n",
    "\n",
    "import warnings\n",
    "\n",
    "def bisection(N_low, N_high, sample_function):\n",
    "    \"\"\"\n",
    "    :param N_low: Low guess for the intersection\n",
    "    :param N_high: High guess for the intersection\n",
    "    :param sample_function: Function for which to find the zero crossing\n",
    "    :return: The zero crossing\n",
    "    \"\"\"\n",
    "    # print(f\"Running bisection to find S between {N_low} and {N_high}...\", end=\"\")\n",
    "\n",
    "    a = N_low\n",
    "    b = N_high\n",
    "    f = sample_function\n",
    "\n",
    "    TOL = 1e-9\n",
    "\n",
    "    if a > b:\n",
    "      print('Error: a > b!')\n",
    "      return -1\n",
    "\n",
    "    value_a = f(a)\n",
    "\n",
    "    for i in range(1000):\n",
    "      c = (a + b) / 2.\n",
    "      value_c = f(c)\n",
    "\n",
    "      if value_c == 0 or (b - a) / 2. < TOL:\n",
    "          # print(f\" Found {c:.2f}\")\n",
    "          return c\n",
    "\n",
    "      if np.sign(value_c) == np.sign(value_a):\n",
    "          a = c\n",
    "          value_a = value_c\n",
    "      else:\n",
    "          b = c\n",
    "\n",
    "    print(\"Bisection failed to converge!\")\n",
    "\n",
    "def nchoosek_rooted(n, k, root):\n",
    "    \"\"\"\n",
    "    To avoid numerical errors, an implementation of N choose K where the root is resolved in between\n",
    "    :return: (n choose k)^(1/root)\n",
    "    \"\"\"\n",
    "    y = 1.0\n",
    "    for i in range(k):\n",
    "        y = y * ((n - (k - i - 1.)) / (k - i))**(1. / root)\n",
    "    return y\n",
    "\n",
    "def compute_risk(S, confidence, support):\n",
    "  with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    return 1. - ((confidence / S) ** (1. / (S - support))) * (1. / nchoosek_rooted(S, support, S - support))\n",
    "\n",
    "def find_sample_size(support, risk, confidence):\n",
    "  risk_function = lambda S, support: compute_risk(S, confidence, support)      # Scenario Optimization guarantee for any support\n",
    "  max_risk_function = lambda S: risk - risk_function(S, support)               # \"\" for the specified support limit\n",
    "\n",
    "  S_low = support+1\n",
    "  S_high = 500000\n",
    "\n",
    "  S_double = bisection(S_low, S_high, max_risk_function)\n",
    "  S = np.floor(S_double) + 1\n",
    "\n",
    "  return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79aa79f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "# To ensure humans do not collide with the robot during initialization\n",
    "# and are within field of view of the robot\n",
    "\n",
    "def is_within_distance(pos1, pos2, distance):\n",
    "    return np.linalg.norm(np.array(pos1) - np.array(pos2)) <= distance\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\"Calculate the angle between two vectors.\"\"\"\n",
    "    v1_u = v1 / np.linalg.norm(v1)\n",
    "    v2_u = v2 / np.linalg.norm(v2)\n",
    "    angle = np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "    cross = np.cross(np.append(v1_u, 0), np.append(v2_u, 0))\n",
    "    if cross[2] < 0:\n",
    "        angle = -angle\n",
    "    return angle\n",
    "\n",
    "def is_within_fov(robot_pos, robot_orientation, target_pos, fov=90):\n",
    "    \"\"\"Check if target_pos is within the field of view of the robot.\"\"\"\n",
    "    direction_vector = np.array([np.cos(np.deg2rad(robot_orientation)), np.sin(np.deg2rad(robot_orientation))])\n",
    "    target_vector = np.array(target_pos) - np.array(robot_pos)\n",
    "    angle = np.rad2deg(angle_between(direction_vector, target_vector))\n",
    "    return -fov/2 < angle < fov/2\n",
    "\n",
    "# To generate constraint coefficients given human and robot positions\n",
    "def get_constraint_coeff(robot_pos, human_pos, r):\n",
    "    u = human_pos - robot_pos\n",
    "    A = u / np.linalg.norm(u)\n",
    "    a = A[0]\n",
    "    b = A[1]\n",
    "    c = r - A[0]*human_pos[0] - A[1]*human_pos[1]\n",
    "    return np.array([a, b, c]) # Linear inequality: ax + by + c <= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8391514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_symmetric(matrix):\n",
    "    \"\"\"\n",
    "    Checks if the given matrix is symmetric (A == A^T).\n",
    "    Raises a ValueError if it is not symmetric.\n",
    "    \"\"\"\n",
    "    if not np.allclose(matrix, matrix.T):  # Checks if A == A^T (within numerical tolerance)\n",
    "        raise ValueError(\"Matrix is not symmetric!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c921f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Function\n",
    "## To get predictions for a scene\n",
    "## and calculate the constraint coefficients\n",
    "\n",
    "col_radius = 1.0  # Collision radius for agents\n",
    "buffer_dist = 0.5 # Buufer distance considered when choosing robot position\n",
    "vision_radius = 12.0  # Vision radius for robots\n",
    "prediction_horizon = 12\n",
    "\n",
    "def get_scene_graph_data(scene_batch: SceneBatch, scene_data):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    enc = traj_predictor.scene_encoder(scene_batch)\n",
    "    pred = traj_predictor.incremental_forward(\n",
    "        batch=scene_batch,\n",
    "        prediction_horizon=prediction_horizon,\n",
    "        num_samples=1,\n",
    "        full_dist=True\n",
    "    )\n",
    "\n",
    "    # All humans in the scene\n",
    "    scene_data[\"Human Positions\"] = obs.curr_agent_state[:, :2].cpu().numpy()\n",
    "\n",
    "    # Agent to World frame transformations\n",
    "    agents_to_world_tf = obs.agents_from_world_tf[:, :2, :2].cpu().numpy()\n",
    "    # Append predicted positions of humans to occupied positions\n",
    "    occupied_pos = [pos for pos in scene_data[\"Human Positions\"]]\n",
    "    # Initiate adjaceny matrix\n",
    "    adjacency_matrix = np.zeros((len(obs.agent_name), len(obs.agent_name)), dtype=int)\n",
    "\n",
    "    # Loop through all humans\n",
    "    for idx, human in enumerate(obs.agent_name):\n",
    "        # Append predicted positions to occupied positions (after transformation to world frame)\n",
    "        pred_world_frame = pred[human].reshape(prediction_horizon, 2) @ agents_to_world_tf[idx, :, :] + scene_data[\"Human Positions\"][idx, :]\n",
    "        for jdx in range(prediction_horizon):\n",
    "            occupied_pos.append(pred_world_frame[jdx, :])\n",
    "        # Create adjacency matrix\n",
    "        current_state = scene_data[\"Human Positions\"][idx, :2]\n",
    "        agent_to_world_tf = agents_to_world_tf[idx, :, :]\n",
    "        if obs.num_neigh[idx] > 0:\n",
    "            for neigh_pos in obs.neigh_hist[idx, :obs.num_neigh[idx].item(), -1, :2].cpu().numpy():\n",
    "                neigh_pos = neigh_pos @ agent_to_world_tf + current_state\n",
    "                for jdx, agent_pos in enumerate(obs.curr_agent_state[:, :2].cpu().numpy()):\n",
    "                    if np.linalg.norm(neigh_pos - agent_pos) < 1e-5:\n",
    "                        adjacency_matrix[idx, jdx] = 1\n",
    "        # Store human encodings\n",
    "        scene_data[\"Encodings\"].append(enc[human].cpu().numpy().flatten())\n",
    "\n",
    "    scene_data[\"Adjacency Matrix\"] = adjacency_matrix\n",
    "    check_symmetric(scene_data[\"Adjacency Matrix\"])\n",
    "\n",
    "    # Assign appropriate robot position\n",
    "    # print(\"Occupied positions:\", occupied_pos)\n",
    "    while True: # Generate a random position for the robot\n",
    "        # Ensure the robot's position does not overlap with any occupied positions\n",
    "        robot_position = (random.uniform(-vision_radius, vision_radius), random.uniform(-vision_radius, vision_radius))\n",
    "        if not any(is_within_distance(robot_position, pos, col_radius+buffer_dist) for pos in occupied_pos):\n",
    "            break\n",
    "    scene_data[\"Robot Pose\"] = [robot_position[0], robot_position[1]]\n",
    "\n",
    "    return obs, scene_data\n",
    "\n",
    "\n",
    "def get_constr_data(t, S, obs: AgentBatch, scene_data):\n",
    "\n",
    "    _, preds, _, _ = trajectron.incremental_forward(\n",
    "        timestep=t,\n",
    "        obs=obs,\n",
    "        maps=None,\n",
    "        prediction_horizon=prediction_horizon,\n",
    "        num_samples=int(S),\n",
    "        full_dist=False\n",
    "    )\n",
    "\n",
    "    # Agent to World frame transformations\n",
    "    agents_to_world_tf = obs.agents_from_world_tf[:, :2, :2].cpu().numpy()\n",
    "\n",
    "    constraint_coeffs = []\n",
    "    for idx, human in enumerate(obs.agent_name):\n",
    "        # print(\"Pred shape:\", preds[human].shape)\n",
    "        constraint_pos_st = preds[human][:, :, 0, :].reshape(int(S), 2) # TODO: change the timestpe of prediction positions being considered\n",
    "        constraint_pos = constraint_pos_st @ agents_to_world_tf[idx, :, :] + scene_data[\"Human Positions\"][idx, :]\n",
    "        # print(\"Constraint positions:\", constraint_pos)\n",
    "        for sidx in range(int(S)):\n",
    "            constraint_coeffs.append(get_constraint_coeff(scene_data[\"Robot Pose\"], constraint_pos[sidx, :], col_radius))\n",
    "            # print(\"Constraint Coeffs:\", constraint_coeffs[-1])\n",
    "    scene_data[\"Constraint Coefficients\"] = constraint_coeffs\n",
    "  \n",
    "    return scene_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import support_pred.halfplane_module as hm\n",
    "\n",
    "logger = hm.Logger(\"logfile.txt\", True)\n",
    "processor = hm.HalfplaneIntersectionProcessor(500, 10)\n",
    "processor.set_logger(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f37a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4,  2],\n",
       "       [ 3,  8,  2],\n",
       "       [ 4,  8,  2],\n",
       "       [ 4, 10,  5],\n",
       "       [-1, -2,  2]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# constraints = np.array([[3,4,2],[3,8,2],[4,8,2], [4,10,5], [-1,-2,2]])\n",
    "# support = processor.get_support_size(constraints)\n",
    "# support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fdbbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6c8803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
